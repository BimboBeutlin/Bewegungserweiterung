# Bewegungserweiterung - Eingangserkennung mit RealSense & LiDAR

Dieses Projekt nutzt eine Intel RealSense Tiefenkamera (und optional einen LiDAR) zur automatischen Erkennung von EingÃ¤ngen/TÃ¼ren fÃ¼r autonome Navigation.

## ğŸ¯ Funktionen

- **Tiefenbasierte Eingangserkennung**: Erkennt TÃ¼rÃ¶ffnungen durch Analyse von TiefensprÃ¼ngen
- **Vertikale Strukturerkennung**: Identifiziert TÃ¼rrahmen mittels Kantenerkennung
- **3D-Positionsbestimmung**: Berechnet exakte 3D-Koordinaten der EingÃ¤nge
- **Dimensionsmessung**: Misst Breite und HÃ¶he der EingÃ¤nge
- **BefahrbarkeitsprÃ¼fung**: Validiert ob EingÃ¤nge passierbar sind
- **Multi-Sensor-Fusion**: Kombiniert Tiefenkamera und LiDAR-Daten

## ğŸ“ Dateien

- `entrance_detection.py` - Einfache Eingangserkennung (Einstieg)
- `advanced_entrance_detection.py` - Erweiterte Erkennung mit 3D-Projektion und Filterung
- `opencv_viewer_example.py` - Basis-Beispiel fÃ¼r RealSense
- `python-tutorial-1-depth.py` - Einfaches Tiefendaten-Tutorial

## ğŸš€ Installation

### 1. RealSense SDK installieren (siehe setup.txt)
```bash
# Auf Ubuntu/Linux
pip3 install pyrealsense2
```

### 2. Python-AbhÃ¤ngigkeiten
```bash
pip install opencv-python numpy pyrealsense2
```

## ğŸ’» Verwendung

### Einfache Eingangserkennung
```bash
python entrance_detection.py
```

### Erweiterte Erkennung mit 3D-Berechnung
```bash
python advanced_entrance_detection.py
```

**Steuerung:**
- `q` - Beenden
- `s` - Screenshot speichern

## ğŸ”§ Wie funktioniert die Eingangserkennung?

### 1. Tiefenanalyse
Die Kamera misst die Entfernung zu Objekten. EingÃ¤nge/TÃ¼ren haben charakteristische Eigenschaften:
- **GroÃŸe Tiefenwerte** oder **fehlende Messwerte** (freier Raum)
- **TiefensprÃ¼nge** an den RÃ¤ndern (TÃ¼rrahmen)

### 2. Kantenerkennung
Vertikale Kanten werden erkannt:
- Infrarot-Bild fÃ¼r besseren Kontrast
- Canny-Kantendetektor
- Hough-Transform fÃ¼r Linienerkennung
- Filterung nach vertikalen Linien (TÃ¼rrahmen)

### 3. Kandidatenvalidierung
Jeder Kandidat wird geprÃ¼ft:
- âœ“ Breite: 0,7 - 2,5 Meter
- âœ“ HÃ¶he: mindestens 1,8 Meter (befahrbar)
- âœ“ Aspect Ratio: hÃ¶her als breit
- âœ“ Entfernung: < 5 Meter

### 4. 3D-Projektion
Pixel-Koordinaten werden in 3D-Weltkoordinaten umgerechnet:
```python
point_3d = rs.rs2_deproject_pixel_to_point(intrinsics, [x, y], depth)
```

## ğŸ¤– LiDAR-Integration

Der LiDAR kann zusÃ¤tzliche Informationen liefern:

### Vorteile der Kombination:
- **LiDAR**: 360Â° 2D-Scan auf BodenhÃ¶he, prÃ¤zise Distanzen
- **Tiefenkamera**: 3D-Information, HÃ¶henerkennung, visuelle Details

### Verwendung:
```python
detector = MultiSensorEntranceDetector(use_lidar=True)

# LiDAR-Daten integrieren
lidar_scan = [...]  # Array von (angle, distance)
detector.integrate_lidar_data(lidar_scan)
```

### Beispiel LiDAR-Interface:
```python
# FÃ¼r RPLidar
from rplidar import RPLidar

lidar = RPLidar('/dev/ttyUSB0')
for scan in lidar.iter_scans():
    detector.integrate_lidar_data(scan)
```

## ğŸ“Š Parameter anpassen

In `advanced_entrance_detection.py`:
```python
self.min_entrance_width = 0.7      # Minimale Breite (Meter)
self.max_entrance_width = 2.5      # Maximale Breite
self.min_entrance_height = 1.8     # MindesthÃ¶he fÃ¼r Befahrbarkeit
self.max_detection_range = 5.0     # Maximale Erkennungsdistanz
```

## ğŸ“ Algorithmus im Detail

1. **Frame-Erfassung**: Depth + Color + IR Streams synchronized
2. **Filterung**: Spatial, Temporal, Hole-Filling Filter
3. **Tiefensprung-Detektion**: Sobel-Filter fÃ¼r Gradienten
4. **Strukturerkennung**: Vertikale Linien im IR-Bild
5. **Kandidatenfindung**: Linienpaare analysieren
6. **Dimensionsberechnung**: 3D-Projektion
7. **Validierung**: Konfidenz-Score berechnen
8. **Ausgabe**: Visualisierung + 3D-Koordinaten

## ğŸ› Troubleshooting

### Kamera nicht gefunden
```bash
# USB-Verbindung prÃ¼fen
rs-enumerate-devices

# Rechte setzen (Linux)
sudo usermod -a -G plugdev $USER
```

### Schlechte Erkennung
- Beleuchtung verbessern
- Kamera-Parameter anpassen (Exposure)
- Filter-Schwellwerte tunen
- Mindestabstand einhalten (> 0,5m)

### Performance-Probleme
- AuflÃ¶sung reduzieren (320x240)
- FPS reduzieren (15 statt 30)
- Nur Depth-Stream nutzen

## ğŸ“š Ressourcen

- [Intel RealSense Documentation](https://dev.intelrealsense.com/)
- [OpenCV Tutorials](https://docs.opencv.org/)
- [RealSense Python Examples](https://github.com/IntelRealSense/librealsense/tree/master/wrappers/python/examples)

## ğŸ¯ NÃ¤chste Schritte

1. **Echte LiDAR-Integration** implementieren
2. **SLAM** fÃ¼r Kartierung hinzufÃ¼gen
3. **Navigation** basierend auf erkannten EingÃ¤ngen
4. **Machine Learning** fÃ¼r robustere Erkennung
5. **ROS-Integration** fÃ¼r Roboter-Plattformen
