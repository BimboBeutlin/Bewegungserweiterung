# Bewegungserweiterung - Eingangserkennung mit RealSense & LiDAR

Dieses Projekt nutzt eine Intel RealSense Tiefenkamera (und optional einen LiDAR) zur automatischen Erkennung von EingÃ¤ngen/TÃ¼ren fÃ¼r autonome Navigation.

## ğŸ¯ Funktionen

- **Tiefenbasierte Eingangserkennung**: Erkennt TÃ¼rÃ¶ffnungen durch Analyse von TiefensprÃ¼ngen
- **Vertikale Strukturerkennung**: Identifiziert TÃ¼rrahmen mittels Kantenerkennung
- **3D-Positionsbestimmung**: Berechnet exakte 3D-Koordinaten der EingÃ¤nge
- **Dimensionsmessung**: Misst Breite und HÃ¶he der EingÃ¤nge
- **BefahrbarkeitsprÃ¼fung**: Validiert ob EingÃ¤nge passierbar sind
- **Multi-Sensor-Fusion**: Kombiniert Tiefenkamera und LiDAR-Daten

## ğŸ“ Dateien

- `entrance_detection.py` - Einfache Eingangserkennung (Einstieg)
- `advanced_entrance_detection.py` - Erweiterte Erkennung mit 3D-Projektion und Filterung
- `opencv_viewer_example.py` - Basis-Beispiel fÃ¼r RealSense
- `python-tutorial-1-depth.py` - Einfaches Tiefendaten-Tutorial

## ğŸš€ Installation

### 1. RealSense SDK installieren (siehe setup.txt)
```bash
# Auf Ubuntu/Linux
pip3 install pyrealsense2
```

### 2. Python-AbhÃ¤ngigkeiten
```bash
pip install opencv-python numpy pyrealsense2
```

## ï¿½ Quick Start

### Installation
```bash
# Python-AbhÃ¤ngigkeiten
pip install opencv-python numpy pyrealsense2

# Optional: LiDAR-Support
pip install rplidar-roboticia matplotlib
```

### Hauptsystem starten
```bash
python adaptive_height_control.py
```

**Steuerung:**
- `q` - Beenden
- `s` - Screenshot
- `e` - Emergency Stop (Toggle)

## ï¿½ MVP-Anforderungen (Meilensteine)

### âœ… Phase 1: Setup (Abgeschlossen)
- [x] Hardware-Integration (RealSense)
- [x] Basis-Tiefenerkennung
- [x] Visualisierung

### ğŸ”„ Phase 2: Schnittstellen (MS2 - Aktuell)
- [x] LiDAR-Daten auslesen
- [x] Stereo-Depth-Verarbeitung
- [ ] **Unitree SDK Integration** ğŸ¯
  - [ ] `SetBodyHeight()` implementieren
  - [ ] `SetPostureMode()` implementieren
  - [ ] Bewegungs-Feedback auslesen

### ğŸ“‹ Phase 3: Logik (MS3 - Next)
- [x] Durchgangs-Geometrie-Extraktion
- [x] HÃ¶henberechnung mit Sicherheit
- [x] State Machine (4 Modi)
- [ ] **SDK-Ansteuerung verbinden**
- [ ] Bewegungsablauf implementieren
- [ ] Safety-Override testen

### ğŸ¯ Phase 4: Integration & Test
- [ ] End-to-End Tests
- [ ] Performance-Optimierung
- [ ] Feldtests in echter Umgebung
- [ ] Dokumentation finalisieren

## ğŸ§® Technische Details

### Haltungs-Modi

| Modus | HÃ¶he | Verwendung |
|-------|------|------------|
| **NORMAL** | 30cm | Freie Fahrt, keine Hindernisse |
| **NIEDRIG** | 15cm | DurchgÃ¤nge 15-25cm HÃ¶he |
| **LIEGEND** | 8cm | DurchgÃ¤nge 10-15cm HÃ¶he |
| **BLOCKIERT** | - | < 10cm, zu eng, Stopp |

### Sicherheitsparameter
- **Sicherheitsabstand**: 5-10cm Ã¼ber DurchgangshÃ¶he
- **AnnÃ¤herung**: Stopp bei 0,5m vor Durchgang
- **Geschwindigkeit**: 0,1 m/s beim Durchqueren
- **Max. Neigung**: 30Â° (schrÃ¤ge Decken)

### Sensor-Reichweiten
- **Tiefenkamera**: 0,3m - 3,0m (optimal: 0,5m - 2,0m)
- **LiDAR**: 0,1m - 12m
- **Min. Durchgangsbreite**: 35cm (Roboter + Sicherheit)
- **Min. DurchgangshÃ¶he**: 10cm (absolute Grenze)

## ğŸ”§ Code-Struktur

### Hauptklasse: `AdaptiveHeightController`

```python
# Initialisierung
controller = AdaptiveHeightController(use_lidar=False)

# Hauptschleife
controller.run()

# Interner Ablauf pro Frame:
# 1. detect_ceiling_obstacle()     # INPUT
# 2. calculate_passage_geometry()  # PROCESSING  
# 3. decide_posture()              # DECISION
# 4. actuate_height_change()       # OUTPUT
```

### Datenstrukturen

```python
@dataclass
class PassageGeometry:
    height: float          # DurchgangshÃ¶he in Metern
    width: float           # Breite in Metern
    distance: float        # Entfernung zum Durchgang
    tilt_angle: float      # Neigung in Grad
    confidence: float      # ErkennungsqualitÃ¤t 0-1

@dataclass  
class RobotState:
    current_height: float       # Aktuelle KÃ¶rperhÃ¶he
    current_mode: PostureMode   # NORMAL/LOW/PRONE/BLOCKED
    is_adjusting: bool          # Gerade am Anpassen?
    emergency_stop: bool        # Notaus aktiv?
```

## ğŸ“ Algorithmen im Detail

### 1. Deckenerkennung
```python
# Obere BildhÃ¤lfte analysieren
ceiling_roi = depth_image[10%:60%, :]

# Nahe Hindernisse finden (< 3m)
close_obstacles = ceiling_distances < 3.0

# Kontur-Extraktion â†’ Bounding Box
```

### 2. HÃ¶henberechnung
```python
# 3D-Projektion der Unterkante
bottom_3d = rs2_deproject_pixel_to_point([x, y], depth)

# HÃ¶he = Abstand Boden â†’ Hindernis
passage_height = abs(bottom_3d[1] - ground_3d[1])

# Mit Sicherheit
target_height = passage_height - safety_clearance
```

### 3. State Machine
```python
if target_height >= 0.25:
    return NORMAL, 0.30
elif target_height >= 0.15:
    return LOW, target_height  # Ducken
elif target_height >= 0.10:
    return PRONE, 0.08         # Hinlegen
else:
    return BLOCKED, current    # Zu eng
```

## ğŸ”Œ Unitree SDK Integration (TODO)

### BenÃ¶tigte Funktionen
```python
# In adaptive_height_control.py, Methode: actuate_height_change()

# TODO: Ersetze Stub durch echte SDK-Calls:

from unitree_sdk import RobotInterface  # Beispiel

robot = RobotInterface()

# HÃ¶he setzen
robot.SetBodyHeight(target_height)  # in Metern

# Haltung wechseln
robot.SetPostureMode(mode)  # "stand", "crouch", "prone"

# Status abfragen
current_height = robot.GetBodyHeight()
is_stable = robot.IsStable()

# Notaus
robot.EmergencyStop()
```

### Integration Steps
1. Unitree SDK installieren/importieren
2. `actuate_height_change()` anpassen
3. Bewegungs-Feedback implementieren
4. Safety-Checks mit IMU verbinden
5. Testen mit echtem Roboter

## ğŸ§ª Testing

### Simulation
```bash
# Teste ohne Hardware (mit Recording)
python adaptive_height_control.py
# Halte Objekte vor Kamera in verschiedenen HÃ¶hen
```

### Mit Roboter
1. Roboter in sicherer Umgebung platzieren
2. Niedrige Hindernisse (20cm, 15cm, 10cm) vorbereiten
3. System starten
4. Langsam Hindernisse annÃ¤hern
5. Beobachte HÃ¶henanpassung

### TestfÃ¤lle
- [ ] Normaler Durchgang (>25cm) â†’ Keine Anpassung
- [ ] Niedriger Durchgang (20cm) â†’ Ducken
- [ ] Sehr niedriger Durchgang (12cm) â†’ Hinlegen
- [ ] Zu enger Durchgang (8cm) â†’ Blockiert
- [ ] SchrÃ¤ge Decke (15Â° Neigung) â†’ Anpassung
- [ ] Emergency Stop â†’ Sofortiger Halt

## ğŸ“š Weitere Ressourcen

## ğŸ“š Weitere Ressourcen

- **PROJECT_SPEC.md** - VollstÃ¤ndige technische Spezifikation
- [Intel RealSense Documentation](https://dev.intelrealsense.com/)
- [Unitree Robotics](https://www.unitree.com/)
- [OpenCV Tutorials](https://docs.opencv.org/)

## ğŸ‘¥ Projekt-Info

**Repository**: github.com/eliasbuergin/Bewegungserweiterung  
**Entwickler**: Elias BÃ¼rgin  
**Projekt**: MPEC - Motion Path Extension and Control  
**Zweck**: Autonome HÃ¶hlenerkundung mit Unitree GO2

---

## ğŸ“ NÃ¤chste Schritte fÃ¼r Entwicklung

### PrioritÃ¤t 1: SDK-Integration (MS2)
```bash
# TODO:
1. Unitree SDK installieren
2. actuate_height_change() mit echten Calls ersetzen
3. Feedback-Loop implementieren (GetBodyHeight)
4. Safety-Checks mit IMU verbinden
```

### PrioritÃ¤t 2: Bewegungsablauf (MS3)
```bash
# TODO:
1. AnnÃ¤herungs-Sequenz (langsam bis 0.5m)
2. HÃ¶henanpassung (2-3 Sekunden warten)
3. Durchquerung (0.1 m/s, Kollisionserkennung)
4. ZurÃ¼ck zu Normal (nach Durchgang)
```

### PrioritÃ¤t 3: Robustheit
```bash
# TODO:
1. Mehrfach-Messungen fÃ¼r StabilitÃ¤t
2. Kalman-Filter fÃ¼r HÃ¶henschÃ¤tzung
3. Fehlerbehandlung (Sensorfehler, Timeouts)
4. Logging & Telemetrie
```

**Status**: MVP in Entwicklung | Version 0.3.0 | Stand: 1. Dezember 2025
